\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[spanish]{babel}
\setlength{\parskip}{4.5pt}
\usepackage{booktabs}
\usepackage[top=3cm]{geometry}
\usepackage{float}


\title{Reporte Tarea 2 Parte 2 Ciencia de Datos}
\author{Alfredo Bistrain, Guillermo Aguilar, Oswaldo Bueno}
\date{Septiembre 2025}

\begin{document}

\maketitle

\section*{Objetivos}

El código implementado tiene como objetivo estudiar el comportamiento de diversos 
clasificadores supervisados en un entorno controlado, en el cual las distribuciones 
de las clases son conocidas y corresponden a distribuciones normales multivariadas. 
Este diseño experimental permite comparar el desempeño empírico de los clasificadores 
con el clasificador óptimo de Bayes, el cual se construye a partir de las densidades 
verdaderas y las probabilidades a priori fijadas.

\subsection*{Descripción del código}

El programa genera datos sintéticos a partir de dos clases $Y \in \{0,1\}$ con 
priors $\pi_0$ y $\pi_1$. Para cada clase se especifican parámetros de medias 
$\mu_k$ y matrices de covarianza $\Sigma_k$. Con estos datos se simulan muestras 
independientes y se entrenan diferentes clasificadores:

\begin{itemize}
    \item \textbf{Bayes}: clasificador óptimo bajo las densidades gaussianas verdaderas.
    \item \textbf{Naive Bayes gaussiano}: asume independencia condicional entre predictores.
    \item \textbf{LDA (Linear Discriminant Analysis)}: válido bajo $\Sigma_0 = \Sigma_1$.
    \item \textbf{QDA (Quadratic Discriminant Analysis)}: válido bajo $\Sigma_0 \neq \Sigma_1$.
    \item \textbf{Criterio de Fisher en 1D}: proyección lineal y clasificación con umbral.
    \item \textbf{k-NN}: clasificador de vecinos más cercanos con distintos valores de $k$.
\end{itemize}

El código contempla cuatro escenarios principales:
\begin{enumerate}
    \item Covarianzas iguales ($\Sigma_0 = \Sigma_1$), donde LDA coincide con Bayes.
    \item Covarianzas distintas ($\Sigma_0 \neq \Sigma_1$), donde QDA coincide con Bayes.
    \item Desbalance de clases ($\pi_1 = 0.2$), para evaluar efectos de clases minoritarias.
    \item Covarianzas mal condicionadas con correlaciones fuertes, lo que genera inestabilidad numérica.
\end{enumerate}

Para cada escenario se realizan réplicas Monte Carlo ($R=20$) y se varía tanto 
el tamaño muestral por clase ($n \in \{50,100,200,500\}$) como el número de vecinos 
en k-NN ($k \in \{1,3,5,11,21\}$). Los riesgos de clasificación se estiman mediante 
validación cruzada estratificada (5-fold), además de calcularse el riesgo verdadero 
de Bayes por integración Monte Carlo.

Los resultados se almacenan en tablas y se exportan en formato \LaTeX\ como 
``media $\pm$ desviación estándar''. Asimismo, se generan figuras comparativas 
de $L(g)$ contra $n$, de $L(\text{k-NN})$ contra $k$ y de las brechas 
$L(g)-L(\text{Bayes})$ para evaluar la proximidad de cada método al óptimo.

\subsection*{Discusión de resultados}

En el escenario con covarianzas iguales, LDA logra acercarse rápidamente al riesgo 
óptimo de Bayes conforme aumenta el tamaño muestral, mientras que QDA tiende a 
sobreajustar en muestras pequeñas. El clasificador de Fisher en 1D presenta un 
desempeño intermedio, útil como aproximación lineal simple. Los métodos de 
k-NN muestran alta varianza para $k$ pequeños (especialmente $k=1$) y mejor 
estabilidad para valores moderados como $k=11$ o $k=21$, aunque sin alcanzar 
la optimalidad de LDA.

En el escenario con covarianzas distintas, QDA se comporta de manera óptima y 
converge al riesgo de Bayes, mientras que LDA incurre en un sesgo debido a la 
suposición incorrecta de igualdad de covarianzas. Naive Bayes tiende a tener 
rendimiento inferior, dado que suponer independencia condicional no se ajusta 
a la realidad de correlaciones moderadas entre las variables.

El escenario desbalanceado resalta que los clasificadores tienden a favorecer la 
clase mayoritaria, reduciendo la sensibilidad en la clase minoritaria. Esto motiva 
el uso de técnicas de reponderación o ajuste de umbrales en aplicaciones prácticas.

Finalmente, en el escenario mal condicionado con correlaciones fuertes, los métodos 
basados en inversión de matrices (LDA y QDA) muestran inestabilidad numérica, 
evidenciando sensibilidad a la multicolinealidad. En contraste, k-NN y Naive Bayes 
resultan más robustos en esta situación, aunque a costa de un mayor riesgo global.
\subsection*{Discusión de los resultados experimentales}

Los resultados de las simulaciones se ilustran en las Figuras~\ref{fig:lda_optimo}--\ref{fig:validacion_bayes}, donde se representan la evolución del riesgo de clasificación y las comparaciones con el clasificador de Bayes.

\begin{itemize}
    \item \textbf{Figura~\ref{fig:lda_optimo}: L(g) vs n en el escenario con covarianzas iguales.} 
    Se observa que el clasificador LDA converge rápidamente al riesgo óptimo de Bayes a medida que el tamaño muestral aumenta, confirmando la teoría de que LDA es óptimo bajo homocedasticidad. QDA, en cambio, muestra una mayor varianza y sobreajuste cuando $n$ es pequeño, pero tiende a estabilizarse conforme crece el tamaño de la muestra.

    \item \textbf{Figura~\ref{fig:knn_corr}: L(k-NN) vs k en el escenario de correlaciones fuertes.} 
    El desempeño de k-NN depende fuertemente de la elección de $k$. Con $k=1$ se obtiene baja sesgo pero alta varianza, mientras que valores intermedios ($k=5$ a $k=11$) logran un equilibrio adecuado. Para $k$ muy grandes, el riesgo se incrementa al suavizar en exceso la frontera de decisión. En todos los casos, k-NN no alcanza el nivel óptimo de Bayes, pero resulta relativamente robusto frente al mal condicionamiento de las covarianzas.

    \item \textbf{Figura~\ref{fig:brechas}: Brechas $L(g)-L(\text{Bayes})$ en correlaciones fuertes.} 
    Tanto LDA como QDA presentan un sesgo positivo respecto al clasificador óptimo, evidenciando limitaciones bajo multicolinealidad. LDA resulta especialmente afectado, mostrando una brecha mayor incluso con $n$ grandes. QDA se aproxima mejor, aunque también incurre en desviaciones.

    \item \textbf{Figura~\ref{fig:validacion_bayes}: Comparación validación cruzada vs riesgo verdadero de Bayes.} 
    Se aprecia que los riesgos estimados por validación tienden a sobreestimar el riesgo verdadero. Esta sobreestimación se debe al sesgo inherente de la validación cruzada en muestras finitas, pero su variabilidad disminuye con $n$. La diagonal $y=x$ indica el ideal en el que la validación coincidiría exactamente con el riesgo verdadero.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Figure_0.png}
    \caption{Evolución de $L(g)$ en función de $n$ en el escenario LDA óptimo.}
    \label{fig:lda_optimo}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Figure_1.png}
    \caption{Evolución de $L(k\text{-NN})$ en función de $k$ bajo correlaciones fuertes.}
    \label{fig:knn_corr}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Figure_2.png}
    \caption{Brechas $L(g)-L(\text{Bayes})$ para LDA y QDA en correlaciones fuertes.}
    \label{fig:brechas}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Figure_3.png}
    \caption{Comparación entre riesgos estimados por validación cruzada y riesgo verdadero de Bayes.}
    \label{fig:validacion_bayes}
\end{figure}

\subsection*{Conclusiones}

El estudio confirma que el clasificador de Bayes constituye la referencia óptima. 
Los resultados muestran que:
\begin{itemize}
    \item LDA es muy competitivo bajo homocedasticidad y tamaños muestrales moderados.
    \item QDA es preferible cuando las covarianzas difieren significativamente, aunque 
    requiere más datos para estimar adecuadamente $\Sigma_k$.
    \item k-NN ofrece flexibilidad y no depende de supuestos paramétricos, pero 
    su desempeño varía fuertemente con $k$ y $n$.
    \item Los escenarios desbalanceados y con covarianzas mal condicionadas 
    ponen de manifiesto limitaciones prácticas y la necesidad de validar los 
    supuestos del modelo.
\end{itemize}

En suma, este tipo de simulaciones controladas permiten no sólo contrastar métodos 
en condiciones ideales, sino también entender sus limitaciones cuando los supuestos 
se violan, proporcionando guía para aplicaciones reales.



\end{document}
